{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "import mmh3\n",
    "class CountMin:\n",
    "    def __init__(self,w,d):\n",
    "        self.w=w\n",
    "        self.d=d\n",
    "        self.sketch=[[0 for i in range(w)] for j in range(d)]\n",
    "        self.seeds=[1234,561,76,9565]\n",
    "    def insert(self,key):\n",
    "        for i in range(self.d):\n",
    "            hash_val=mmh3.hash(key,seed=self.seeds[i])\n",
    "            self.sketch[i][hash_val%self.w]+=1\n",
    "    def query(self,key):\n",
    "        min_val=-1\n",
    "        for i in range(self.d):\n",
    "            hash_val=mmh3.hash(key,seed=self.seeds[i])\n",
    "            if min_val==-1 or self.sketch[i][hash_val%self.w]<min_val:\n",
    "                min_val=self.sketch[i][hash_val%self.w]\n",
    "        return min_val\n",
    "class BloomFilter:\n",
    "    def __init__(self,w,d):\n",
    "        self.w=w\n",
    "        self.d=d\n",
    "        self.sketch=[0 for i in range(w)]\n",
    "        self.seeds=[1234,561,76,9565]\n",
    "    def insert(self,key):\n",
    "        for i in range(self.d):\n",
    "            hash_val=mmh3.hash(key,seed=self.seeds[i])\n",
    "            self.sketch[hash_val%self.w]=1\n",
    "    def query(self,key):\n",
    "        flag=1\n",
    "        for i in range(self.d):\n",
    "            hash_val=mmh3.hash(key,seed=self.seeds[i])\n",
    "            if self.sketch[hash_val%self.w]==0:\n",
    "                flag=0\n",
    "                break\n",
    "        return flag\n",
    "    def reset(self):\n",
    "        for i in range(self.w):\n",
    "            self.sketch[i]=0\n",
    "class KeywordSketch:\n",
    "    def __init__(self,w,d):\n",
    "        self.w=w\n",
    "        self.d=d\n",
    "        self.sketch=[[[\"\",0] for i in range(d)] for j in range(w)]\n",
    "        self.seed=67483\n",
    "    def insert(self,doc,word):\n",
    "        hash_val=doc\n",
    "        bucket_idx=hash_val%self.w\n",
    "        min_val=-1\n",
    "        min_idx=-1\n",
    "        empty_idx=-1\n",
    "        for i in range(self.d):\n",
    "            if self.sketch[bucket_idx][i][0]==word:\n",
    "                self.sketch[bucket_idx][i][1]+=1\n",
    "                return\n",
    "            elif self.sketch[bucket_idx][i][0]==\"\":\n",
    "                empty_idx=i\n",
    "            elif min_val==-1 or self.sketch[bucket_idx][i][1]<min_val:\n",
    "                min_idx=i\n",
    "        if empty_idx!=-1:\n",
    "            self.sketch[bucket_idx][empty_idx][0]=word\n",
    "            self.sketch[bucket_idx][empty_idx][1]=1\n",
    "            return\n",
    "        self.sketch[bucket_idx][min_idx][0]=word\n",
    "        self.sketch[bucket_idx][min_idx][1]=1\n",
    "    def query(self,doc):\n",
    "        hash_val=doc\n",
    "        bucket_idx=hash_val%self.w\n",
    "        return self.sketch[bucket_idx]\n",
    "    \n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T14:12:12.509126Z",
     "start_time": "2024-12-16T14:12:12.490756Z"
    }
   },
   "id": "6e55ef38a231ed53",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "def query_similarity(keyword_sketch:KeywordSketch,cm:CountMin,doc1,doc2,total_doc):\n",
    "    wordlst1=keyword_sketch.query(doc1)\n",
    "    wordlst2=keyword_sketch.query(doc2)\n",
    "    word_weight1={}\n",
    "    word_weight2={}\n",
    "    sum_cnt1=0\n",
    "    sum_cnt2=0\n",
    "    min_weight_sum=0\n",
    "    max_weight_sum=0\n",
    "    for pair in wordlst1:\n",
    "        sum_cnt1+=pair[1]\n",
    "        word_weight1[pair[0]]=pair[1]\n",
    "    for pair in wordlst2:\n",
    "        sum_cnt2+=pair[1]\n",
    "        word_weight2[pair[0]]=pair[1]\n",
    "    for word in word_weight1:\n",
    "        idf=math.log2(total_doc/(cm.query(word)+1))\n",
    "        tf1=word_weight1[word]/sum_cnt1\n",
    "        w1=idf*tf1\n",
    "        tf2=word_weight2.get(word,0)/sum_cnt2\n",
    "        w2=idf*tf2\n",
    "        min_weight_sum+=min(w1,w2)\n",
    "        max_weight_sum+=max(w1,w2)\n",
    "    for word in word_weight2:\n",
    "        if word in word_weight1:\n",
    "            continue\n",
    "        idf=math.log2(total_doc/(cm.query(word)+1))\n",
    "        tf1=word_weight1.get(word,0)/sum_cnt1\n",
    "        w1=idf*tf1\n",
    "        tf2=word_weight2.get(word,0)/sum_cnt2\n",
    "        w2=idf*tf2\n",
    "        min_weight_sum+=min(w1,w2)\n",
    "        max_weight_sum+=max(w1,w2)\n",
    "    return min_weight_sum/max_weight_sum\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T14:12:15.475300Z",
     "start_time": "2024-12-16T14:12:15.469324Z"
    }
   },
   "id": "306206d0dab33765",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "all_data=os.listdir(\"data\")\n",
    "doc_id=0\n",
    "vis={}\n",
    "limit=20\n",
    "word_idf={}\n",
    "doc_word_cnt=[]\n",
    "for data in all_data:\n",
    "    vis.clear()\n",
    "    word_cnt={}\n",
    "    data_file=open(\"data/\"+data,\"r\")\n",
    "    lines=data_file.readlines()\n",
    "    for line in lines:\n",
    "        src,dst=line.split()\n",
    "        if vis.get(src,0)==0:\n",
    "            vis[src]=1\n",
    "            word_cnt[src]=1\n",
    "            word_idf[src]=word_idf.get(src,0)+1\n",
    "        else:\n",
    "            word_cnt[src]+=1\n",
    "        if vis.get(dst,0)==0:\n",
    "            vis[dst]=1\n",
    "            word_cnt[dst]=1\n",
    "            word_idf[dst]=word_idf.get(dst,0)+1\n",
    "        else:\n",
    "            word_cnt[src]+=1\n",
    "    doc_word_cnt.append(word_cnt)\n",
    "    doc_id+=1\n",
    "    print(doc_id+\" done\")\n",
    "    if doc_id==limit:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68be43055f18517",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "doc_sim={}\n",
    "for i in range(doc_id):\n",
    "    for j in range(i+1,doc_id):\n",
    "        code=i*(doc_id+1)+j\n",
    "        min_weight_sum=0\n",
    "        max_weight_sum=0\n",
    "        for word in doc_word_cnt[i]:\n",
    "            idf=math.log2(doc_id/(word_idf[word]+1))\n",
    "            tf1=doc_word_cnt[i][word]\n",
    "            w1=idf*tf1\n",
    "            tf2=doc_word_cnt[j].get(word,0)\n",
    "            w2=tf2*idf\n",
    "            min_weight_sum+=min(w1,w2)\n",
    "            max_weight_sum+=max(w1,w2)\n",
    "        for word in doc_word_cnt[j]:\n",
    "            idf=math.log2(doc_id/(word_idf[word]+1))\n",
    "            tf1=doc_word_cnt[i].get(word,0)\n",
    "            if tf1>0:\n",
    "                continue\n",
    "            w1=idf*tf1\n",
    "            tf2=doc_word_cnt[j].get(word,0)\n",
    "            w2=tf2*idf\n",
    "            min_weight_sum+=min(w1,w2)\n",
    "            max_weight_sum+=max(w1,w2)\n",
    "        doc_sim[code]=min_weight_sum/max_weight_sum"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8884c311844477a8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "all_data=os.listdir(\"data\")\n",
    "doc_id=0\n",
    "cm=CountMin(100000,4)\n",
    "bf=BloomFilter(10000,4)\n",
    "ks=KeywordSketch(1000,10)\n",
    "for data in all_data:\n",
    "    bf.reset()\n",
    "    data_file=open(\"data/\"+data,\"r\")\n",
    "    lines=data_file.readlines()\n",
    "    for line in lines:\n",
    "        src,dst=line.split()\n",
    "        if not bf.query(src):\n",
    "            bf.insert(src)\n",
    "            cm.insert(src)\n",
    "        ks.insert(doc_id,src)\n",
    "        if not bf.query(dst):\n",
    "            bf.insert(dst)\n",
    "            cm.insert(dst)\n",
    "        ks.insert(doc_id,dst)\n",
    "    doc_id+=1\n",
    "    if limit==doc_id:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "are=0\n",
    "pairs=0\n",
    "for i in range(0,doc_id):\n",
    "    for j in range(i+1,doc_id):\n",
    "        es_sim=query_similarity(ks,cm,i,j,doc_id)\n",
    "        ac_sim=doc_sim[i*(doc_id+1)+j]\n",
    "        if(ac_sim==0):\n",
    "            continue\n",
    "        are+=abs(es_sim-ac_sim)/ac_sim\n",
    "        pairs+=1\n",
    "are/=pairs\n",
    "print(\"are: \"+str(are))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24b2f631cdc2bedf",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
