{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abad39a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68be43055f18517",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "all_data=open(\"text_dataset/processed_text_dataset.txt\",\"r\")\n",
    "doc_id=0\n",
    "vis={}\n",
    "limit=10000\n",
    "word_idf={}\n",
    "doc_word_cnt=[]\n",
    "for line in all_data.readlines():\n",
    "    vis.clear()\n",
    "    word_cnt={}\n",
    "    all_words=line.split(\" \")\n",
    "    for word in all_words:\n",
    "        if vis.get(word,0)==0:\n",
    "            vis[word]=1\n",
    "            word_cnt[word]=1\n",
    "            word_idf[word]=word_idf.get(word,0)+1\n",
    "        else:\n",
    "            word_cnt[word]+=1\n",
    "    doc_word_cnt.append(word_cnt)\n",
    "    doc_id+=1\n",
    "    print(str(doc_id)+\" done\")\n",
    "    if doc_id==limit:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc48abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#each set top-100 normalized tf-idf\n",
    "all_set_topk=[]\n",
    "for i in range(len(doc_word_cnt)):\n",
    "    word_cnt=doc_word_cnt[i]\n",
    "    total_cnt=sum(word_cnt.values())\n",
    "    tf_idf={}\n",
    "    for word in word_cnt:\n",
    "        tf=word_cnt[word]/total_cnt\n",
    "        idf=math.log(doc_id/(word_idf[word]+1))\n",
    "        tf_idf[word]=tf*idf\n",
    "    sorted_tf_idf=sorted(tf_idf.items(),key=lambda x:x[1],reverse=True)\n",
    "    while len(sorted_tf_idf)<100:\n",
    "        sorted_tf_idf.append((\"\",0.0))\n",
    "    top_k=sorted_tf_idf[:100]\n",
    "    #min-max normalization\n",
    "    min_val=min([x[1] for x in top_k])\n",
    "    max_val=max([x[1] for x in top_k])\n",
    "    for j in range(len(top_k)):\n",
    "        word=top_k[j][0]\n",
    "        val=top_k[j][1]\n",
    "        norm_val=(val-min_val)/(max_val-min_val)\n",
    "        top_k[j]=(word,norm_val)\n",
    "    all_set_topk.append(top_k)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b8170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 计算平均 top-k 权重\n",
    "average_topk = []\n",
    "for i in range(100):\n",
    "    word_sum = 0.0\n",
    "    for j in range(len(all_set_topk)):\n",
    "        word_sum += all_set_topk[j][i][1]\n",
    "    average_topk.append(word_sum / len(all_set_topk))\n",
    "\n",
    "x = np.arange(1, len(average_topk)+1)\n",
    "\n",
    "# 1) 平均 rank–weight 曲线\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.plot(x, average_topk, marker='x', linestyle='-', color='b')\n",
    "plt.xlabel(\"Rank\",fontsize=16)\n",
    "plt.ylabel(\"Average Weight\",fontsize=16)\n",
    "plt.title(\"Average Rank-Weight Curve\",fontsize=16)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.savefig(\"average_rank_weight_curve.eps\", dpi=300, bbox_inches='tight',format='eps')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8884c311844477a8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_sim={}\n",
    "for i in range(100):\n",
    "    for j in range(i+1,100):\n",
    "        code=i*100001+j\n",
    "        min_weight_sum=0\n",
    "        max_weight_sum=0\n",
    "        sum_cnt1=0\n",
    "        sum_cnt2=0\n",
    "        for word in doc_word_cnt[i]:\n",
    "            sum_cnt1+=doc_word_cnt[i][word]\n",
    "        for word in doc_word_cnt[j]:\n",
    "            sum_cnt2+=doc_word_cnt[j][word]\n",
    "        for word in doc_word_cnt[i]:\n",
    "            idf=math.log2(doc_id/(word_idf[word]+1))\n",
    "            tf1=doc_word_cnt[i][word]/sum_cnt1\n",
    "            w1=idf*tf1\n",
    "            tf2=doc_word_cnt[j].get(word,0)/sum_cnt2\n",
    "            w2=tf2*idf\n",
    "            min_weight_sum+=min(w1,w2)\n",
    "            max_weight_sum+=max(w1,w2)\n",
    "        for word in doc_word_cnt[j]:\n",
    "            idf=math.log2(doc_id/(word_idf[word]+1))\n",
    "            tf1=doc_word_cnt[i].get(word,0)\n",
    "            if tf1>0:\n",
    "                continue\n",
    "            w1=idf*tf1\n",
    "            tf2=doc_word_cnt[j].get(word,0)\n",
    "            w2=tf2*idf\n",
    "            min_weight_sum+=min(w1,w2)\n",
    "            max_weight_sum+=max(w1,w2)\n",
    "        doc_sim[code]=min_weight_sum/max_weight_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706fad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topkmae=[]\n",
    "topkare=[]\n",
    "sumpairs=0\n",
    "for k in range(20,120,20):\n",
    "    summae=0\n",
    "    sumare=0\n",
    "    for i in range(100):\n",
    "        for j in range(i+1,100):\n",
    "            #use top-k words to compute similarity\n",
    "            code=i*100001+j\n",
    "            if doc_sim.get(code,0)==0:\n",
    "                continue\n",
    "            sumpairs+=1\n",
    "            min_weight_sum=0\n",
    "            max_weight_sum=0\n",
    "            topk1={}\n",
    "            topk2={}\n",
    "            for word in all_set_topk[i][:k]:\n",
    "                topk1[word[0]]=word[1]\n",
    "            for word in all_set_topk[j][:k]:\n",
    "                topk2[word[0]]=word[1]\n",
    "            for word in topk1:\n",
    "                min_weight_sum+=min(topk1[word],topk2.get(word,0))\n",
    "                max_weight_sum+=max(topk1[word],topk2.get(word,0))\n",
    "            for word in topk2:\n",
    "                if word in topk1:\n",
    "                    continue\n",
    "                min_weight_sum+=min(topk2[word],0)\n",
    "                max_weight_sum+=max(topk2[word],0)\n",
    "            est=min_weight_sum/max_weight_sum\n",
    "            mae=abs(est-doc_sim[code])\n",
    "            are=abs(est-doc_sim[code])/doc_sim[code]\n",
    "            summae+=mae\n",
    "            sumare+=are\n",
    "    topkmae.append(summae/sumpairs)  # 4950 is the number of unique pairs in 100 documents\n",
    "    topkare.append(sumare/sumpairs)\n",
    "    \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e83e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw top-k MAE curve\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.plot(range(20,120,20), topkmae, marker='x', linestyle='-', color='r')\n",
    "plt.ylim([0,0.05])\n",
    "plt.xlabel(\"Top-k\", fontsize=16)\n",
    "plt.ylabel(\"MAE\", fontsize=16)\n",
    "# plt.title(\"Top-k MAE Curve\", fontsize=16)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0537f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "plt.plot(range(20,120,20), topkare, marker='o', linestyle='-', color='r')\n",
    "plt.xlabel(\"Top-k\", fontsize=16)\n",
    "plt.ylabel(\"ARE\", fontsize=16)\n",
    "plt.title(\"Top-k ARE Curve\", fontsize=16)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
